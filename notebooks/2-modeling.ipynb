{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd().endswith('notebooks'):\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.features import KeywordProcessor\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cv_results(model, X, y, model_name=None, scoring=None, cv=5, n_jobs=-1):\n",
    "    \"\"\"Compute aggregated metrics using cross-validation\"\"\"\n",
    "    if scoring is None:\n",
    "        scoring = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    \n",
    "    cv_results = cross_validate(model, X, y, scoring=scoring, cv=cv, n_jobs=n_jobs)\n",
    "    cv_results_agg = pd.DataFrame(cv_results).mean()\n",
    "    \n",
    "    if model_name:\n",
    "        cv_results_agg = cv_results_agg.rename(model_name)\n",
    "\n",
    "    return cv_results_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df_train = pd.read_csv('data/train.csv', index_col='id')\n",
    "df_test = pd.read_csv('data/test.csv', index_col='id')\n",
    "\n",
    "# Split dataset\n",
    "X = df_train.drop(columns='target')\n",
    "y = df_train['target']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80       874\n",
      "           1       0.73      0.76      0.74       649\n",
      "\n",
      "    accuracy                           0.78      1523\n",
      "   macro avg       0.77      0.77      0.77      1523\n",
      "weighted avg       0.78      0.78      0.78      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Keeping it for reference :)\n",
    "\n",
    "# Define the keyword processing pipeline\n",
    "keyword_processor = Pipeline(steps=[\n",
    "    ('keyword_processor', KeywordProcessor()),  # Custom keyword processing transformer\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # One-hot encoding for processed keywords\n",
    "])\n",
    "\n",
    "# Define the text processing component using TfidfVectorizer\n",
    "text_processor = TfidfVectorizer(stop_words='english')  # Vectorization while removing English stop words\n",
    "\n",
    "# Combine keyword and text processing in a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('keyword_processor', keyword_processor, ['keyword']),  # Apply keyword processing to 'keyword' column\n",
    "        ('text_preprocessor', text_processor, 'text'),  # Apply text vectorization to 'text' column\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the complete model pipeline\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Preprocessing step for both keywords and text\n",
    "    ('clf', LogisticRegressionCV(class_weight='balanced'))  # Logistic regression classifier with balanced class weights\n",
    "])\n",
    "\n",
    "# Fit the model pipeline to the training data\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred = model_pipeline.predict(X_val)\n",
    "\n",
    "# Print the classification report to evaluate model performance\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --  Baseline Model -- ##\n",
    "baseline_preprocessor = ColumnTransformer([\n",
    "    ('text_processor', CountVectorizer(), 'text')\n",
    "])\n",
    "\n",
    "baseline_model = Pipeline(steps=[\n",
    "    ('preprocessor', baseline_preprocessor),\n",
    "    ('clf', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "## -- Common Preprocessor -- ##\n",
    "\n",
    "# Define the keyword processing pipeline\n",
    "keyword_processor = Pipeline(steps=[\n",
    "    ('keyword_processor', KeywordProcessor()),           # Custom keyword processing transformer\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # One-hot encoding for processed keywords\n",
    "])\n",
    "\n",
    "# Define the text processing component using TfidfVectorizer\n",
    "text_processor = TfidfVectorizer(stop_words='english')   # Vectorization while removing English stop words\n",
    "\n",
    "# Combine keyword and text processing in a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('keyword_processor', keyword_processor, ['keyword']),  # Apply keyword processing to 'keyword' column\n",
    "        ('text_preprocessor', text_processor, 'text'),          # Apply text vectorization to 'text' column\n",
    "    ]\n",
    ")\n",
    "\n",
    "## -- Logistic Regression -- ##\n",
    "\n",
    "lr_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', LogisticRegressionCV(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "## -- SVM -- ##\n",
    "\n",
    "svc_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "## -- Catboost -- ##\n",
    "\n",
    "lgbm_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', LGBMClassifier(verbosity=-1, random_seed=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict(\n",
    "    baseline = baseline_model,\n",
    "    lr = lr_model,\n",
    "    svc = svc_model,\n",
    "    lgbm = lgbm_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-16 21:34:03.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mTraining model baseline\u001b[0m\n",
      "\u001b[32m2024-10-16 21:34:04.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mTraining model lr\u001b[0m\n",
      "\u001b[32m2024-10-16 21:34:06.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mTraining model svc\u001b[0m\n",
      "\u001b[32m2024-10-16 21:34:11.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mTraining model lgbm\u001b[0m\n",
      "\u001b[32m2024-10-16 21:36:57.769\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[32m\u001b[1mAll models trained!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cv_results = []\n",
    "\n",
    "for model_name,model in models.items():\n",
    "    logger.info(f'Training model {model_name}')\n",
    "    cv_result = compute_cv_results(model, X, y, model_name=model_name)\n",
    "    cv_results.append(cv_result)\n",
    "\n",
    "logger.success('All models trained!')\n",
    "\n",
    "df_cv_results = pd.DataFrame(cv_results).sort_values('test_balanced_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_score_cols = ['fit_time','score_time']\n",
    "metric_cols = [col for col in df_cv_results.columns if col not in fit_score_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4a3d4_row0_col0, #T_4a3d4_row0_col1, #T_4a3d4_row0_col2, #T_4a3d4_row0_col3, #T_4a3d4_row0_col4, #T_4a3d4_row0_col6, #T_4a3d4_row0_col7, #T_4a3d4_row3_col5 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4a3d4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4a3d4_level0_col0\" class=\"col_heading level0 col0\" >fit_time</th>\n",
       "      <th id=\"T_4a3d4_level0_col1\" class=\"col_heading level0 col1\" >score_time</th>\n",
       "      <th id=\"T_4a3d4_level0_col2\" class=\"col_heading level0 col2\" >test_accuracy</th>\n",
       "      <th id=\"T_4a3d4_level0_col3\" class=\"col_heading level0 col3\" >test_balanced_accuracy</th>\n",
       "      <th id=\"T_4a3d4_level0_col4\" class=\"col_heading level0 col4\" >test_precision</th>\n",
       "      <th id=\"T_4a3d4_level0_col5\" class=\"col_heading level0 col5\" >test_recall</th>\n",
       "      <th id=\"T_4a3d4_level0_col6\" class=\"col_heading level0 col6\" >test_f1</th>\n",
       "      <th id=\"T_4a3d4_level0_col7\" class=\"col_heading level0 col7\" >test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4a3d4_level0_row0\" class=\"row_heading level0 row0\" >baseline</th>\n",
       "      <td id=\"T_4a3d4_row0_col0\" class=\"data row0 col0\" >0.160165</td>\n",
       "      <td id=\"T_4a3d4_row0_col1\" class=\"data row0 col1\" >0.028522</td>\n",
       "      <td id=\"T_4a3d4_row0_col2\" class=\"data row0 col2\" >0.709845</td>\n",
       "      <td id=\"T_4a3d4_row0_col3\" class=\"data row0 col3\" >0.692103</td>\n",
       "      <td id=\"T_4a3d4_row0_col4\" class=\"data row0 col4\" >0.704152</td>\n",
       "      <td id=\"T_4a3d4_row0_col5\" class=\"data row0 col5\" >0.565896</td>\n",
       "      <td id=\"T_4a3d4_row0_col6\" class=\"data row0 col6\" >0.624368</td>\n",
       "      <td id=\"T_4a3d4_row0_col7\" class=\"data row0 col7\" >0.752665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a3d4_level0_row1\" class=\"row_heading level0 row1\" >lgbm</th>\n",
       "      <td id=\"T_4a3d4_row1_col0\" class=\"data row1 col0\" >164.179091</td>\n",
       "      <td id=\"T_4a3d4_row1_col1\" class=\"data row1 col1\" >0.188268</td>\n",
       "      <td id=\"T_4a3d4_row1_col2\" class=\"data row1 col2\" >0.637475</td>\n",
       "      <td id=\"T_4a3d4_row1_col3\" class=\"data row1 col3\" >0.606341</td>\n",
       "      <td id=\"T_4a3d4_row1_col4\" class=\"data row1 col4\" >0.636139</td>\n",
       "      <td id=\"T_4a3d4_row1_col5\" class=\"data row1 col5\" >0.384916</td>\n",
       "      <td id=\"T_4a3d4_row1_col6\" class=\"data row1 col6\" >0.475952</td>\n",
       "      <td id=\"T_4a3d4_row1_col7\" class=\"data row1 col7\" >0.667382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a3d4_level0_row2\" class=\"row_heading level0 row2\" >svc</th>\n",
       "      <td id=\"T_4a3d4_row2_col0\" class=\"data row2 col0\" >3.311143</td>\n",
       "      <td id=\"T_4a3d4_row2_col1\" class=\"data row2 col1\" >1.206605</td>\n",
       "      <td id=\"T_4a3d4_row2_col2\" class=\"data row2 col2\" >0.620004</td>\n",
       "      <td id=\"T_4a3d4_row2_col3\" class=\"data row2 col3\" >0.604236</td>\n",
       "      <td id=\"T_4a3d4_row2_col4\" class=\"data row2 col4\" >0.579266</td>\n",
       "      <td id=\"T_4a3d4_row2_col5\" class=\"data row2 col5\" >0.491939</td>\n",
       "      <td id=\"T_4a3d4_row2_col6\" class=\"data row2 col6\" >0.520372</td>\n",
       "      <td id=\"T_4a3d4_row2_col7\" class=\"data row2 col7\" >0.571464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a3d4_level0_row3\" class=\"row_heading level0 row3\" >lr</th>\n",
       "      <td id=\"T_4a3d4_row3_col0\" class=\"data row3 col0\" >1.077388</td>\n",
       "      <td id=\"T_4a3d4_row3_col1\" class=\"data row3 col1\" >0.119373</td>\n",
       "      <td id=\"T_4a3d4_row3_col2\" class=\"data row3 col2\" >0.604637</td>\n",
       "      <td id=\"T_4a3d4_row3_col3\" class=\"data row3 col3\" >0.602035</td>\n",
       "      <td id=\"T_4a3d4_row3_col4\" class=\"data row3 col4\" >0.540179</td>\n",
       "      <td id=\"T_4a3d4_row3_col5\" class=\"data row3 col5\" >0.583347</td>\n",
       "      <td id=\"T_4a3d4_row3_col6\" class=\"data row3 col6\" >0.554771</td>\n",
       "      <td id=\"T_4a3d4_row3_col7\" class=\"data row3 col7\" >0.570438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa3a91dfc20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_cv_results\n",
    "    .style\n",
    "    .highlight_min(subset=fit_score_cols)\n",
    "    .highlight_max(subset=metric_cols)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
